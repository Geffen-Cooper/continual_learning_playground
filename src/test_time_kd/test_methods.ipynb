{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from train import *\n",
    "from torchvision import datasets, transforms, models\n",
    "from matplotlib.pyplot import figure\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v3_large(weights='DEFAULT').to('cuda')\n",
    "# model64 = models.mobilenet_v3_large()\n",
    "# model64.load_state_dict(torch.load(\"best_modelsv3/best_batch_i1081020.pth\")['model_state_dict'])\n",
    "model128 = models.mobilenet_v3_small()\n",
    "model128.classifier[0] = torch.nn.Linear(576,1280)\n",
    "model128.classifier[3] = torch.nn.Linear(1280,1000)\n",
    "model128.load_state_dict(torch.load(\"best_batch_i162153.pth\")['model_state_dict'])\n",
    "# model128 = models.mobilenet_v3_small()\n",
    "# model128.classifier[0] = torch.nn.Linear(576,1280)\n",
    "# model128.classifier[3] = torch.nn.Linear(1280,1000)\n",
    "# model128.load_state_dict(torch.load(\"mnv3s/best_batch_i342323v3_small_frozen_head1676029877.1912067.pth\")['model_state_dict'])\n",
    "model128.to('cuda')\n",
    "model.eval()\n",
    "model128.eval()\n",
    "\n",
    "activationT = {}\n",
    "activationS = {}\n",
    "def get_activationT(name):\n",
    "    def hook(model, input, output):\n",
    "        activationT[name] = output.detach()\n",
    "    return hook\n",
    "def get_activationS(name):\n",
    "    def hook(model, input, output):\n",
    "        activationS[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.classifier[0].register_forward_hook(get_activationT('emb'))\n",
    "model128.classifier[0].register_forward_hook(get_activationS('emb'))\n",
    "corruptions = ['gaussian_noise','impulse_noise','shot_noise','defocus_blur','glass_blur','motion_blur','zoom_blur','snow','frost','fog','brightness','contrast','elastic_transform','jpeg_compression','pixelate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_embds,clean_labels,clean_preds = torch.load(\"embds/clean224.pt\")\n",
    "clean_embds128,clean_labels128,clean_preds128 = torch.load(\"embds/clean128.pt\")\n",
    "corr_embds = []\n",
    "corr_labels = []\n",
    "corr_preds = []\n",
    "corr_embds128 = []\n",
    "corr_labels128 = []\n",
    "corr_preds128 = []\n",
    "corr_embds64 = []\n",
    "corr_labels64 = []\n",
    "corr_preds64 = []\n",
    "for i,corr in enumerate(corruptions):\n",
    "    e,l,p = torch.load(\"embds/corr224_\"+corr+\".pt\")\n",
    "    e128,l128,p128 = torch.load(\"embds/corr128_\"+corr+\".pt\")\n",
    "    # e64,l64,p64 = torch.load(\"embds/corr64_\"+corr+\".pt\")\n",
    "    corr_embds.append(e)\n",
    "    corr_labels.append(l)\n",
    "    corr_preds.append(p)\n",
    "    corr_embds128.append(e128)\n",
    "    corr_labels128.append(l128)\n",
    "    corr_preds128.append(p128)\n",
    "    # corr_embds64.append(e64)\n",
    "    # corr_labels64.append(l64)\n",
    "    # corr_preds64.append(p64)\n",
    "\n",
    "class FC(torch.nn.Module):\n",
    "    def __init__(self,feats):\n",
    "      super(FC, self).__init__()\n",
    "      self.c = torch.nn.Linear(feats,1000)\n",
    "    def forward(self,x):\n",
    "      return self.c(x)\n",
    "fcs = FC(1280).eval()\n",
    "fct = FC(1280).eval()\n",
    "with torch.no_grad():\n",
    "  fcs.c.weight[:,:] = model128.classifier[3].weight[:,:]\n",
    "  fcs.c.bias[:] = model128.classifier[3].bias[:]\n",
    "  fct.c.weight[:,:] = model.classifier[3].weight[:,:]\n",
    "  fct.c.bias[:] = model.classifier[3].bias[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "methods should follow a modular structure by inheriting from\n",
    "the abstract base class 'Policy'.\n",
    "'''\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "CHOOSE_STUDENT = False\n",
    "CHOOSE_TEACHER = True\n",
    "\n",
    "class Policy(ABC):\n",
    "    # provide the student cost, teacher cost, and budget for the internal parameters\n",
    "    @abstractmethod\n",
    "    def initialize(self,student_cost: int, teacher_cost: int, budget: int):\n",
    "        pass\n",
    "\n",
    "    # execute the policy by giving it the next sample (student embedding tensor)\n",
    "    # the policy returns a bool: 0 for student, 1 for teacher/label\n",
    "    @abstractmethod\n",
    "    def execute(self, next_sample: torch.Tensor) -> bool:\n",
    "        pass\n",
    "\n",
    "    # reset the policy for new round of execution, clear internal state\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    # name of the policy\n",
    "    @abstractmethod\n",
    "    def __str__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class EvalPolicy():\n",
    "    # takes in a list of policies (type Policy)\n",
    "    def __init__(self,policies: list, input_samples: torch.Tensor, student_results: torch.Tensor, \\\n",
    "                teacher_results: torch.Tensor, student_cost: int, teacher_cost: int, budgets: torch.Tensor) -> None:\n",
    "        # input parameters\n",
    "        self.policies = policies\n",
    "        self.input_samples = input_samples\n",
    "        self.student_results = student_results\n",
    "        self.teacher_results = teacher_results\n",
    "        self.student_cost = student_cost\n",
    "        self.teacher_cost = teacher_cost\n",
    "        self.budgets = budgets\n",
    "\n",
    "        # additional variables\n",
    "        self.decisions = torch.zeros((len(policies),len(budgets),len(input_samples)))\n",
    "        self.costs = torch.zeros((len(policies),len(budgets),len(input_samples)))\n",
    "        self.results = torch.zeros((len(policies),len(budgets),len(input_samples)))\n",
    "\n",
    "        self.final_costs = torch.zeros((len(policies),len(budgets)))\n",
    "        self.final_accuracies = torch.zeros((len(policies),len(budgets)))\n",
    "    \n",
    "    def evaluate(self):\n",
    "        print(\"# ===================== Starting Evaluation ===================== #\")\n",
    "        # evaluate each policy\n",
    "        for policy_i,policy in enumerate(tqdm(self.policies)):\n",
    "            print(\"Policy:\",str(policy))\n",
    "            for budget_i,budget in enumerate(tqdm(self.budgets)):\n",
    "                policy.reset()\n",
    "                policy.initialize(self.student_cost,self.teacher_cost,budget)\n",
    "                print(f\"Budget: {budget}\")\n",
    "                # for each policy go through evaluation process\n",
    "                for sample_i,sample in enumerate(tqdm(self.input_samples)):\n",
    "                    # get the policy decision\n",
    "                    decision = policy.execute(sample)\n",
    "                    self.decisions[policy_i,budget_i,sample_i] = decision\n",
    "                    # update the policy cost\n",
    "                    self.costs[policy_i,budget_i,sample_i] += self.student_cost if (decision == CHOOSE_STUDENT) else (self.student_cost+self.teacher_cost)\n",
    "                    # check that the policy stays in budget\n",
    "                    assert sum(self.costs[policy_i,budget_i,:sample_i+1])/(sample_i+1) <= budget, \\\n",
    "                        f\"Policy {policy} has average cost {sum(self.costs[policy_i,budget_i,:sample_i+1])/(sample_i+1)} which exceeds budget {budget}.\"\n",
    "                    self.results[policy_i,budget_i,sample_i] = self.student_results[sample_i] if (decision == CHOOSE_STUDENT) else self.teacher_results[sample_i]\n",
    "\n",
    "            # after evaluating the policy, update its final cost and accuracy\n",
    "            self.final_costs[policy_i,budget_i] = torch.sum(self.costs[policy_i,budget_i,:])/len(self.input_samples)\n",
    "            self.final_accuracies[policy_i,budget_i] = torch.sum(self.results[policy_i,budget_i,:])/len(self.input_samples)\n",
    "\n",
    "    def plot_results(self):\n",
    "        for policy_i,policy in self.policies:\n",
    "            plt.scatter(self.final_costs[policy_i,:],self.final_accuracies[policy_i,:],label=str(policy))\n",
    "        for budget_i, budget in self.budgets:\n",
    "            plt.axvline(budget,label=\"budget:\"+str(budget)+\"MACs (M)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPolicy(Policy):\n",
    "    def initialize(self,student_cost,teacher_cost, budget) -> None:\n",
    "        # save policy variables\n",
    "        self.student_cost = student_cost\n",
    "        self.teacher_cost = teacher_cost\n",
    "        self.budget = budget\n",
    "\n",
    "        # set policy threshold based off of budget\n",
    "        # p*student_cost + (1-p)*teacher_cost <= budget\n",
    "        self.p = (teacher_cost-budget)/(teacher_cost-student_cost)\n",
    "\n",
    "        # keep track of avg cost internall so don't exceed budget\n",
    "        self.total_cost = 0\n",
    "        self.total_cost_counts = 0\n",
    "\n",
    "    def execute(self, next_sample: torch.Tensor) -> bool:\n",
    "        # make decision randomly\n",
    "        decision =  torch.rand(1) > self.p\n",
    "\n",
    "        # update cost\n",
    "        new_total_cost = (self.total_cost+self.student_cost) if (decision == 0) else (self.total_cost+self.teacher_cost)\n",
    "\n",
    "        # if exceed threshold, then choose student\n",
    "        if new_total_cost/(self.total_cost_counts+1) > self.budget:\n",
    "            self.total_cost += self.student_cost\n",
    "            return CHOOSE_STUDENT\n",
    "        else:\n",
    "            self.total_cost = new_total_cost\n",
    "        \n",
    "        self.total_cost_counts += 1\n",
    "        return decision\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_cost = 0\n",
    "        self.total_cost_counts = 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Random Policy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cost = 1\n",
    "t_cost = 10\n",
    "budgets = np.linspace(s_cost,t_cost,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71152ab9c07ce901c8cf95cbd74fadea2c31d5b816d92473f31e695d403a1560"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

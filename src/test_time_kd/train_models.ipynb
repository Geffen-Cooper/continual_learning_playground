{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from train import *\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1153050 (0%)] train loss: 3.372, lr: 0.00400000\n",
      "Train Epoch: 0 [51200/1153050 (4%)] train loss: 2.222, lr: 0.00396000\n",
      "Train Epoch: 0 [102400/1153050 (9%)] train loss: 2.365, lr: 0.00392040\n",
      "Train Epoch: 0 [153600/1153050 (13%)] train loss: 1.460, lr: 0.00388120\n",
      "Train Epoch: 0 [204800/1153050 (18%)] train loss: 1.821, lr: 0.00384238\n",
      "Train Epoch: 0 [256000/1153050 (22%)] train loss: 1.813, lr: 0.00380396\n",
      "Train Epoch: 0 [307200/1153050 (27%)] train loss: 2.025, lr: 0.00376592\n",
      "Train Epoch: 0 [358400/1153050 (31%)] train loss: 1.531, lr: 0.00372826\n",
      "Train Epoch: 0 [409600/1153050 (36%)] train loss: 2.174, lr: 0.00369098\n",
      "Train Epoch: 0 [460800/1153050 (40%)] train loss: 1.382, lr: 0.00365407\n",
      "Train Epoch: 0 [512000/1153050 (44%)] train loss: 1.234, lr: 0.00361753\n",
      "Train Epoch: 0 [563200/1153050 (49%)] train loss: 2.042, lr: 0.00358135\n",
      "Train Epoch: 0 [614400/1153050 (53%)] train loss: 1.602, lr: 0.00354554\n",
      "Train Epoch: 0 [665600/1153050 (58%)] train loss: 1.228, lr: 0.00351008\n",
      "Train Epoch: 0 [716800/1153050 (62%)] train loss: 1.768, lr: 0.00347498\n",
      "Train Epoch: 0 [768000/1153050 (67%)] train loss: 2.040, lr: 0.00344023\n",
      "Train Epoch: 0 [819200/1153050 (71%)] train loss: 1.739, lr: 0.00340583\n",
      "Train Epoch: 0 [870400/1153050 (75%)] train loss: 1.816, lr: 0.00337177\n",
      "Train Epoch: 0 [921600/1153050 (80%)] train loss: 1.686, lr: 0.00333806\n",
      "Train Epoch: 0 [972800/1153050 (84%)] train loss: 1.789, lr: 0.00330467\n",
      "Train Epoch: 0 [1024000/1153050 (89%)] train loss: 1.732, lr: 0.00327163\n",
      "Train Epoch: 0 [1075200/1153050 (93%)] train loss: 1.719, lr: 0.00323891\n",
      "Train Epoch: 0 [1126400/1153050 (98%)] train loss: 1.514, lr: 0.00320652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2002/2002 [02:46<00:00, 11.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [468416/1153050 (100%)] train loss: 2.038, val loss: 1.667, val acc: 0.596, top5: 0.826, lr: 0.00317446\n",
      "==================== best validation accuracy ====================\n",
      "epoch: 0, val accuracy: 0.5963143064542566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1153050 (0%)] train loss: 1.671, lr: 0.00317446\n",
      "Train Epoch: 1 [51200/1153050 (4%)] train loss: 1.006, lr: 0.00157136\n",
      "Train Epoch: 1 [102400/1153050 (9%)] train loss: 1.663, lr: 0.00155564\n",
      "Train Epoch: 1 [153600/1153050 (13%)] train loss: 1.757, lr: 0.00154009\n",
      "Train Epoch: 1 [204800/1153050 (18%)] train loss: 1.286, lr: 0.00152469\n",
      "Train Epoch: 1 [256000/1153050 (22%)] train loss: 1.814, lr: 0.00150944\n",
      "Train Epoch: 1 [307200/1153050 (27%)] train loss: 1.234, lr: 0.00149434\n",
      "Train Epoch: 1 [358400/1153050 (31%)] train loss: 1.667, lr: 0.00147940\n",
      "Train Epoch: 1 [409600/1153050 (36%)] train loss: 1.632, lr: 0.00146461\n",
      "Train Epoch: 1 [460800/1153050 (40%)] train loss: 1.284, lr: 0.00144996\n",
      "Train Epoch: 1 [512000/1153050 (44%)] train loss: 1.502, lr: 0.00143546\n",
      "Train Epoch: 1 [563200/1153050 (49%)] train loss: 1.259, lr: 0.00142111\n",
      "Train Epoch: 1 [614400/1153050 (53%)] train loss: 1.182, lr: 0.00140690\n",
      "Train Epoch: 1 [665600/1153050 (58%)] train loss: 1.085, lr: 0.00139283\n",
      "Train Epoch: 1 [716800/1153050 (62%)] train loss: 1.878, lr: 0.00137890\n",
      "Train Epoch: 1 [768000/1153050 (67%)] train loss: 1.649, lr: 0.00136511\n",
      "Train Epoch: 1 [819200/1153050 (71%)] train loss: 1.541, lr: 0.00135146\n",
      "Train Epoch: 1 [870400/1153050 (75%)] train loss: 1.063, lr: 0.00133794\n",
      "Train Epoch: 1 [921600/1153050 (80%)] train loss: 1.467, lr: 0.00132456\n",
      "Train Epoch: 1 [972800/1153050 (84%)] train loss: 1.029, lr: 0.00131132\n",
      "Train Epoch: 1 [1024000/1153050 (89%)] train loss: 1.490, lr: 0.00129821\n",
      "Train Epoch: 1 [1075200/1153050 (93%)] train loss: 1.667, lr: 0.00128522\n",
      "Train Epoch: 1 [1126400/1153050 (98%)] train loss: 1.247, lr: 0.00127237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2002/2002 [02:44<00:00, 12.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [468416/1153050 (100%)] train loss: 1.036, val loss: 1.508, val acc: 0.628, top5: 0.849, lr: 0.00125965\n",
      "==================== best validation accuracy ====================\n",
      "epoch: 1, val accuracy: 0.6284489958397402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [0/1153050 (0%)] train loss: 1.446, lr: 0.00125965\n",
      "Train Epoch: 2 [51200/1153050 (4%)] train loss: 1.485, lr: 0.00062353\n",
      "Train Epoch: 2 [102400/1153050 (9%)] train loss: 1.233, lr: 0.00061729\n",
      "Train Epoch: 2 [153600/1153050 (13%)] train loss: 1.167, lr: 0.00061112\n",
      "Train Epoch: 2 [204800/1153050 (18%)] train loss: 1.268, lr: 0.00060501\n",
      "Train Epoch: 2 [256000/1153050 (22%)] train loss: 1.309, lr: 0.00059896\n",
      "Train Epoch: 2 [307200/1153050 (27%)] train loss: 1.188, lr: 0.00059297\n",
      "Train Epoch: 2 [358400/1153050 (31%)] train loss: 0.998, lr: 0.00058704\n",
      "Train Epoch: 2 [409600/1153050 (36%)] train loss: 1.006, lr: 0.00058117\n",
      "Train Epoch: 2 [460800/1153050 (40%)] train loss: 0.895, lr: 0.00057535\n",
      "Train Epoch: 2 [512000/1153050 (44%)] train loss: 1.371, lr: 0.00056960\n",
      "Train Epoch: 2 [563200/1153050 (49%)] train loss: 2.029, lr: 0.00056391\n",
      "Train Epoch: 2 [614400/1153050 (53%)] train loss: 1.130, lr: 0.00055827\n",
      "Train Epoch: 2 [665600/1153050 (58%)] train loss: 1.335, lr: 0.00055268\n",
      "Train Epoch: 2 [716800/1153050 (62%)] train loss: 1.344, lr: 0.00054716\n",
      "Train Epoch: 2 [768000/1153050 (67%)] train loss: 0.958, lr: 0.00054169\n",
      "Train Epoch: 2 [819200/1153050 (71%)] train loss: 1.123, lr: 0.00053627\n",
      "Train Epoch: 2 [870400/1153050 (75%)] train loss: 1.196, lr: 0.00053091\n",
      "Train Epoch: 2 [921600/1153050 (80%)] train loss: 0.873, lr: 0.00052560\n",
      "Train Epoch: 2 [972800/1153050 (84%)] train loss: 1.152, lr: 0.00052034\n",
      "Train Epoch: 2 [1024000/1153050 (89%)] train loss: 1.118, lr: 0.00051514\n",
      "Train Epoch: 2 [1075200/1153050 (93%)] train loss: 1.401, lr: 0.00050999\n",
      "Train Epoch: 2 [1126400/1153050 (98%)] train loss: 1.132, lr: 0.00050489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2002/2002 [02:30<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [468416/1153050 (100%)] train loss: 1.182, val loss: 1.399, val acc: 0.651, top5: 0.864, lr: 0.00049984\n",
      "==================== best validation accuracy ====================\n",
      "epoch: 2, val accuracy: 0.6507020926184659\n",
      "Train Epoch: 3 [0/1153050 (0%)] train loss: 1.386, lr: 0.00049984\n",
      "Train Epoch: 3 [51200/1153050 (4%)] train loss: 1.412, lr: 0.00024742\n",
      "Train Epoch: 3 [102400/1153050 (9%)] train loss: 1.413, lr: 0.00024495\n",
      "Train Epoch: 3 [153600/1153050 (13%)] train loss: 1.673, lr: 0.00024250\n",
      "Train Epoch: 3 [204800/1153050 (18%)] train loss: 1.260, lr: 0.00024007\n",
      "Train Epoch: 3 [256000/1153050 (22%)] train loss: 0.927, lr: 0.00023767\n",
      "Train Epoch: 3 [307200/1153050 (27%)] train loss: 1.135, lr: 0.00023529\n",
      "Train Epoch: 3 [358400/1153050 (31%)] train loss: 0.762, lr: 0.00023294\n",
      "Train Epoch: 3 [409600/1153050 (36%)] train loss: 1.069, lr: 0.00023061\n",
      "Train Epoch: 3 [460800/1153050 (40%)] train loss: 1.258, lr: 0.00022830\n",
      "Train Epoch: 3 [512000/1153050 (44%)] train loss: 0.919, lr: 0.00022602\n",
      "Train Epoch: 3 [563200/1153050 (49%)] train loss: 1.075, lr: 0.00022376\n",
      "Train Epoch: 3 [614400/1153050 (53%)] train loss: 1.080, lr: 0.00022152\n",
      "Train Epoch: 3 [665600/1153050 (58%)] train loss: 1.070, lr: 0.00021931\n",
      "Train Epoch: 3 [716800/1153050 (62%)] train loss: 1.261, lr: 0.00021712\n",
      "Train Epoch: 3 [768000/1153050 (67%)] train loss: 0.781, lr: 0.00021494\n",
      "Train Epoch: 3 [819200/1153050 (71%)] train loss: 1.236, lr: 0.00021280\n",
      "Train Epoch: 3 [870400/1153050 (75%)] train loss: 1.074, lr: 0.00021067\n",
      "Train Epoch: 3 [921600/1153050 (80%)] train loss: 1.445, lr: 0.00020856\n",
      "Train Epoch: 3 [972800/1153050 (84%)] train loss: 1.282, lr: 0.00020647\n",
      "Train Epoch: 3 [1024000/1153050 (89%)] train loss: 0.992, lr: 0.00020441\n",
      "Train Epoch: 3 [1075200/1153050 (93%)] train loss: 1.425, lr: 0.00020237\n",
      "Train Epoch: 3 [1126400/1153050 (98%)] train loss: 1.104, lr: 0.00020034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2002/2002 [02:29<00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [468416/1153050 (100%)] train loss: 1.101, val loss: 1.363, val acc: 0.659, top5: 0.869, lr: 0.00019834\n",
      "==================== best validation accuracy ====================\n",
      "epoch: 3, val accuracy: 0.6589757799511384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [0/1153050 (0%)] train loss: 0.977, lr: 0.00019834\n",
      "Train Epoch: 4 [51200/1153050 (4%)] train loss: 1.235, lr: 0.00009818\n",
      "Train Epoch: 4 [102400/1153050 (9%)] train loss: 1.154, lr: 0.00009720\n",
      "Train Epoch: 4 [153600/1153050 (13%)] train loss: 1.278, lr: 0.00009622\n",
      "Train Epoch: 4 [204800/1153050 (18%)] train loss: 0.867, lr: 0.00009526\n",
      "Train Epoch: 4 [256000/1153050 (22%)] train loss: 1.093, lr: 0.00009431\n",
      "Train Epoch: 4 [307200/1153050 (27%)] train loss: 1.054, lr: 0.00009337\n",
      "Train Epoch: 4 [358400/1153050 (31%)] train loss: 1.371, lr: 0.00009243\n",
      "Train Epoch: 4 [409600/1153050 (36%)] train loss: 1.441, lr: 0.00009151\n",
      "Train Epoch: 4 [460800/1153050 (40%)] train loss: 1.729, lr: 0.00009059\n",
      "Train Epoch: 4 [512000/1153050 (44%)] train loss: 1.137, lr: 0.00008969\n",
      "Train Epoch: 4 [563200/1153050 (49%)] train loss: 0.979, lr: 0.00008879\n",
      "Train Epoch: 4 [614400/1153050 (53%)] train loss: 1.464, lr: 0.00008790\n",
      "Train Epoch: 4 [665600/1153050 (58%)] train loss: 0.948, lr: 0.00008702\n",
      "Train Epoch: 4 [716800/1153050 (62%)] train loss: 1.522, lr: 0.00008615\n",
      "Train Epoch: 4 [768000/1153050 (67%)] train loss: 1.168, lr: 0.00008529\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gc28692/Projects/continual_learning/continual_learning_playground/src/test_time_kd/train_models.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gc28692/Projects/continual_learning/continual_learning_playground/src/test_time_kd/train_models.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# model = models.mobilenet_v3_large()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gc28692/Projects/continual_learning/continual_learning_playground/src/test_time_kd/train_models.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# model.load_state_dict(torch.load(\"best_batch_i162153.pth\")['model_state_dict'])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gc28692/Projects/continual_learning/continual_learning_playground/src/test_time_kd/train_models.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# train_loader, val_loader,_ = load_tiny_imagenet(64,1234)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gc28692/Projects/continual_learning/continual_learning_playground/src/test_time_kd/train_models.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_loader, val_loader \u001b[39m=\u001b[39m load_imagenet(\u001b[39m64\u001b[39m,\u001b[39m12345\u001b[39m,resize\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gc28692/Projects/continual_learning/continual_learning_playground/src/test_time_kd/train_models.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train(model,train_loader,val_loader,\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m,lr\u001b[39m=\u001b[39;49m\u001b[39m0.004\u001b[39;49m)\n",
      "File \u001b[0;32m~/Projects/continual_learning/continual_learning_playground/src/test_time_kd/train.py:35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_loader, device, lr)\u001b[0m\n\u001b[1;32m     32\u001b[0m batch_iter \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     36\u001b[0m         \u001b[39m# Big Forward\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/cl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/cl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1272\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1271\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1272\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1273\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1274\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/cl/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cl/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m~/anaconda3/envs/cl/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.mobilenet_v3_small(weights='DEFAULT').to('cuda')\n",
    "# model = models.mobilenet_v3_large()\n",
    "# model.load_state_dict(torch.load(\"best_batch_i162153.pth\")['model_state_dict'])\n",
    "# train_loader, val_loader,_ = load_tiny_imagenet(64,1234)\n",
    "train_loader, val_loader = load_imagenet(64,12345,resize=128)\n",
    "train(model,train_loader,val_loader,'cuda',lr=0.004)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = load_imagenet(128,1234,False)\n",
    "test_loader128 = load_imagenet(128,1234,False,resize=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): Conv2dNormActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.mobilenet_v3_large(weights='DEFAULT').to('cuda')\n",
    "model64 = models.mobilenet_v3_small()\n",
    "model64.load_state_dict(torch.load(\"best_batch_i486459.pth\")['model_state_dict'])\n",
    "model64 = model64.to('cuda')\n",
    "model.eval()\n",
    "model64.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [04:20<00:00,  1.50it/s]\n",
      "100%|██████████| 391/391 [03:56<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "acc_clean = validate(model,test_loader,'cuda')\n",
    "acc64_clean = validate(model64,test_loader128,'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobilenet V3 Large Clean (224x224)\n",
      " Top 1: 75.31%\t Top 5: 92.63%\n",
      "Mobilenet V3 Large Clean (64x64)\n",
      " Top 1: 38.34%\t Top 5: 63.53%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mobilenet V3 Large Clean (224x224)\\n Top 1: {:2.2f}%\\t Top 5: {:2.2f}%\".format(acc_clean[0]*100,acc_clean[2]*100))\n",
    "print(\"Mobilenet V3 Large Clean (64x64)\\n Top 1: {:2.2f}%\\t Top 5: {:2.2f}%\".format(acc64_clean[0]*100,acc64_clean[2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "224x224: 234.838456 5483032.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "64x64: 22.863256 5483032.0\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "model = model = models.mobilenet_v3_large()\n",
    "input = torch.randn(1, 3, 224, 224)\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "print(\"224x224:\",macs/1e6,params)\n",
    "\n",
    "input = torch.randn(1, 3, 64, 64)\n",
    "macs, params = profile(model, inputs=(input, ))\n",
    "print(\"64x64:\",macs/1e6,params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71152ab9c07ce901c8cf95cbd74fadea2c31d5b816d92473f31e695d403a1560"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
